{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Day 1\"\n",
        "author: \"Tobias Averbeck\"\n",
        "date: \"March 5th, 2023\"\n",
        "format:\n",
        "  html:\n",
        "    code-fold: false\n",
        "jupyter: python3    \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 1 - The Digit Recognizer (04.03.2023)\n",
        "\n",
        "Today I start with my first projet, the Digit Recognizer, a challenge from Kaggle for beginners. On Kaggle only csv files are uploaded, but I want to learn how to use the original source material, so I download the .gz files from http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "Since the files are stored in binary format, I first need to make them usable for me, to do this I use gzip to read the contents of the .gz files and struct to unzip these files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import gzip\n",
        "import numpy as np\n",
        "import struct\n",
        "import urllib.request\n",
        "\n",
        "def download_mnist(url, filename):\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"Downloading {filename}...\")\n",
        "        urllib.request.urlretrieve(url, filename)\n",
        "        print(f\"Download complete.\")\n",
        "\n",
        "# Download the dataset\n",
        "mnist_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
        "train_images = \"train-images-idx3-ubyte.gz\"\n",
        "train_labels = \"train-labels-idx1-ubyte.gz\"\n",
        "test_images = \"t10k-images-idx3-ubyte.gz\"\n",
        "test_labels = \"t10k-labels-idx1-ubyte.gz\"\n",
        "\n",
        "download_mnist(mnist_url + train_images, train_images)\n",
        "download_mnist(mnist_url + train_labels, train_labels)\n",
        "download_mnist(mnist_url + test_images, test_images)\n",
        "download_mnist(mnist_url + test_labels, test_labels)\n",
        "\n",
        "# Import the dataset\n",
        "def load_mnist(images_path, labels_path):\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        magic, num, rows, cols = struct.unpack(\">IIII\", imgpath.read(16))\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "X_train, y_train = load_mnist(\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\")\n",
        "X_test, y_test = load_mnist(\"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now all that remains is to convert the data into the correct 28x28 pixel form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "My next step is the definition of the model. I know that Convolutional Neural Networks are used for image recognition, so I will do that here too. I start with two convolutional layers and two dense layers and see if I can get it to work. According to the internet it is normal to start with a filter count of 32 in the first conv layer, so I do that here too, followed by a max pooling layer with stride (2,2), which is also standard.\n",
        "I use he_normal as kernel_initalizer, as it is supposed to work well with \"relu\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "img_width = 28\n",
        "img_height = 28\n",
        "num_channels = 1\n",
        "\n",
        "# Inputs to the model\n",
        "input_img = layers.Input(shape=(img_width, img_height, num_channels), \n",
        "                         name=\"image\", \n",
        "                         dtype=\"float32\"\n",
        "                         )\n",
        "\n",
        "# First conv block\n",
        "x = layers.Conv2D(32,\n",
        "                  (3, 3),\n",
        "                  activation=\"relu\",\n",
        "                  kernel_initializer=\"he_normal\",\n",
        "                  name=\"Conv1\",\n",
        "                  )(input_img)\n",
        "\n",
        "# First Max Pooling Layer\n",
        "x = layers.MaxPooling2D((2, 2), name=\"Pool1\")(x)\n",
        "\n",
        "# Second conv block\n",
        "x = layers.Conv2D(64,\n",
        "                  (3, 3),\n",
        "                  activation=\"relu\",\n",
        "                  kernel_initializer=\"he_normal\",\n",
        "                  name=\"Conv2\",\n",
        "                  )(input_img)\n",
        "\n",
        "# Second Max Pooling Layer\n",
        "x = layers.MaxPooling2D((2, 2), name=\"Pool2\")(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After the Conv part comes a Flatten layer, so that the output can be used as input for the following Dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Flatten the input\n",
        "x = layers.Flatten()(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The use of two dense layers in a deep learning model is common in many tasks, including image classification. The first dense layer is used to learn a high-level representation of the input data, while the second dense layer is used to make the final prediction. The 'softmax' activation function is commonly used in the output layer of a deep learning model for classification tasks, as it converts the outputs of the model into a probability distribution over the classes. The 10 in the Dense Layer is because I have 10 digits. The Adam optimizer is a popular choice in deep learning, so I go with that. \"sparse_categorical_crossentropy\" is a loss function used in multi-class classification problems where each sample has a single true label and the goal is to predict the class labels correctly. Accuracy is pretty standard as metric, so I use that here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# First Dense Layer\n",
        "x = layers.Dense(64, activation=\"relu\", name=\"Dense1\")(x)\n",
        "\n",
        "# Second Dense Layer\n",
        "output = layers.Dense(10, activation=\"softmax\", name=\"Dense2\")(x)\n",
        "\n",
        "# Define the model\n",
        "model = models.Model(inputs=input_img, \n",
        "                           outputs=output, \n",
        "                           name=\"Digit_Model\"\n",
        "                           )\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "predictions = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For a first try this looks pretty good, we got an accuracy of 96.2%!\n",
        "\n",
        "At the end, I want to look at where the model failed, for that we'll look at it with matplotlib:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the predicted classes for each sample in X_test\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Set a threshold for the prediction uncertainty\n",
        "uncertainty_threshold = 0.9\n",
        "\n",
        "# Get the indices of the samples with prediction uncertainty above the threshold\n",
        "uncertain_indices = np.where(np.max(predictions, axis=1) < uncertainty_threshold)[0]\n",
        "\n",
        "num_images = 70\n",
        "\n",
        "wrong_indices = [i for i, prediction in enumerate(predicted_classes) if prediction != y_test[i]]\n",
        "rows = num_images // 10 + (num_images % 10 != 0)\n",
        "fig, axs = plt.subplots(rows, 10, figsize=(15, 15), subplot_kw={'xticks': [], 'yticks': []})\n",
        "fig.subplots_adjust(hspace=0.5, wspace=0.05)\n",
        "axs = axs.ravel()\n",
        "for i, index in enumerate(wrong_indices[:num_images]):\n",
        "    axs[i].imshow(X_test[index].reshape(28, 28), cmap=\"gray\")\n",
        "    axs[i].set_title(\"True: {}\\nPredicted: {}\".format(y_test[index], predicted_classes[index]))\n",
        "for i in range(num_images, rows * 10):\n",
        "    fig.delaxes(axs[i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With some of them you can understand why the images were wrongly classified, but others look quite clear. Now we have to do some fine tuning, I will do that in the next blog entry.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}